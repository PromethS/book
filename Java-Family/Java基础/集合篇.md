## Collection
Collection接口是集合类的根接口，Java中没有提供这个接口的直接的实现类。但是却让其被继承产生了两个接口，就是 Set和List。Set中不能包含重复的元素。List是一个有序的集合，可以包含重复的元素，提供了按索引访问的方式。

Map是Java.util包中的另一个接口，它和Collection接口没有关系，是相互独立的，但是都属于集合类的一部分。Map包含了key-value对。Map不能包含重复的key，但是可以包含相同的value。

**Iterator**，所有的集合类，都实现了Iterator接口，这是一个用于遍历集合中元素的接口，主要包含以下三种方法：
1.hasNext()是否还有下一个元素。
2.next()返回下一个元素。
3.remove()删除当前元素。

Collection 和 **Collections**是两个不同的概念。Collection是一个接口，所有的集合类（除Map外）都要继承（实现）自该接口。它提供了对集合对象进行基本操作的通用接口方法。Collections是一个包装类，它包含有各种有关集合操作的静态多态方法（Collections是一个工具类，不能实例化）。

**关系图谱：**

![image](https://520li.oss-cn-hangzhou.aliyuncs.com/img/clipboard-1590157099025.png)

### List（有序、可重复）
List集合代表一个元素有序、可重复的集合，集合中每个元素都有其对应的顺序索引。List集合允许加入重复元素，因为它可以通过索引来访问指定位置的集合元素。List集合默认按元素的添加顺序设置元素的索引。
- **ArrayList**
    - 基于**数组**实现
    - 线程**不安全**
    - **查询速度快，增删慢**
    - 默认容量是10，扩容后是当前容量 * 1.5 + 1
- **LinkedList**
    - 底层使用**双向循环链表**实现
    - 线程**不安全**
    - **查询速度慢，增删快**
- Vector
    - 基于数组实现
    - 查询速度快，增删慢
    - **线程安全**，效率低
    - 默认容量是10，扩容后是当前容量 * 2

### Set（无序、不能重复） 
Set集合类似于一个罐子，"丢进"Set集合里的多个对象之间没有明显的顺序。Set继承自Collection接口，不能包含有重复元素。Set判断两个对象相同不是使用"=="运算符，而是根据**equals**方法。
- 在使用Set集合的时候，应**注意**两点：
    - 1) 为Set集合里的元素的实现类实现一个有效的equals(Object)方法、
    - 2) 对Set的构造函数，传入的Collection参数不能包含重复的元素
- **HashSet**
    - 底层使用**HashMap**实现（Hash表）
    - 存取速度快
- **TreeSet**
    - 底层使用**TreeMap**实现（红黑树）
    - 排序存储
- **LinkedHashSet**
    - 内部使用**LinkedHashMap**，用**双向链表**记录插入顺序

### Queue（FIFO，先进先出）
Queue用于模拟"队列"这种数据结构(先进先出**FIFO**)。队列的头部保存着队列中存放时间最长的元素，队列的尾部保存着队列中存放时间最短的元素。新元素插入(offer)到队列的尾部，访问元素(poll)操作会返回队列头部的元素，队列不允许随机访问队列中的元素。
![image](https://520li.oss-cn-hangzhou.aliyuncs.com/img/clipboard-1590157128063.png)

#### 非阻塞队列（实现了java.util.Queue接口和java.util.AbstractQueue接口）
- **PriorityQueue**
    - 用数组表示的**最小堆**实现
- **ConcurrentLinkedQueue**
    - 基于**链表**实现
    - 使用**volatile + CAS**实现并发安全
- **ConcurrentLinkedDeque**
    - **双向链表**结构的无界并发队列
    - 使用**volatile + CAS**实现并发安全
    - 同时支持**FIFO和FILO（先进后出）**两种操作方式
- 主要方法
    - **add**(E e) : 将元素e插入到队列末尾，如果插入成功，则返回true；如果插入失败（即队列已满），则会抛出异常；
    - **offer**(E e) ：将元素e插入到队列末尾，如果插入成功，则返回true；如果插入失败（即队列已满），则返回false；
    - **remove**() ：移除队首元素，若移除成功，则返回true；如果移除失败（队列为空），则会抛出异常；
    - **poll**() ：移除并获取队首元素，若成功，则返回队首元素；否则返回null；
    - **peek**() ：获取队首元素，若成功，则返回队首元素；否则返回null

#### 阻塞队列
- **ArrayBlockingQueue**
    - 基于数组实现的有界阻塞队列
    - 初始化时需要指定容量
    - 有个**独占锁lock**用来对出入队操作加锁，同时只有**一个线程**可以访问入队出队
    - 可选**公平策略**，默认是false，设置为true则严格按照FIFO顺序，但会降低吞吐量
    - **size**操作加了独占锁，可以确保精确性
- **LinkedBlockingQueue**
    - 基于单向链表实现的无界阻塞队列
    - 默认容量为Integer.MAX_VALUE
    - **两把锁**，一把用于入队，一把用于出队，有效的避免了入队与出队时使用一把锁带来的竞争。在入队与出队都高并发的情况下，性能比ArrayBlockingQueue高很多
- **PriorityBlockingQueue**
    - 基于**最小堆**的无界阻塞队列，类似与PriorityQueue
    - 有个**独占锁lock**用来对出入队操作加锁
- **DelayQueue**
    - 内部使用**PriorityQueue**存放数据
    - 只有在**延迟期**满时才能从中提取元素
- **SychronousQueue**
    - **不存储元素、没有内部容量**的阻塞队列，每个插入操作必须等待另一个线程的对应移除操作
- **LinkedBlockingDeque**
    - 基于**双向链表**的无界阻塞双端队列
- 主要方法
    - **put**(E e) : 用来向队尾存入元素，如果队列满，则等待；
    - **take**() : 用来从队首取元素，如果队列为空，则等待；
    - **offer**(E e,long timeout, TimeUnit unit) : 用来向队尾存入元素，如果队列满，则等待一定的时间，当时间期限达到时，如果还没有插入成功，则返回false；否则返回true；
    - **poll**(long timeout, TimeUnit unit) : 用来从队首取元素，如果队列空，则等待一定的时间，当时间期限达到时，如果取到，则返回null；否则返回取得的元素；

### Map（键值对、键唯一、值不唯一）
Map并**不实现Collection接口**，Map集合中存储的是键值对，键不能重复，值可以重复。根据键得到值，对map集合遍历时先得到键的set集合，对set集合进行遍历，得到相应的值。
- **HashMap**
    - 底层基于数组+链表（红黑色）实现
    - 线程不安全
    - 允许key为null
    - 在1.8前有死循环的风险（扩容时顺序颠倒，导致循环引用）
- **LinkedHashMap**
    - 继承HashMap，实现了插入顺序和访问顺序
    - 基于双向链表实现
    - 可应用于缓存系统的**LRU**（最近最少使用）
    - 可以设置按插入顺序排序，还是访问顺序排序
- **ConcurrentHashMap**
    - 线程安全
    - 基于分段锁（segment）机制，降低锁的颗粒度。在1.8中把锁细化到table级别（链表的头部节点）
- **TreeMap**
    - 底层基于红黑树实现
- **HashTable**
    - 与HashMap类似，增加锁机制，线程安全

## HashMap
### 实现原理分析
HashMap 根据键的**hashCode**值存储数据，大多数情况下可以直接定位到它的值，因而具有**很快的访问速度**，但遍历顺序却是**不确定**的。 HashMap最多只允许一条记录的键为null，允许多条记录的值为null。HashMap**非线程安全**,即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以使用ConcurrentHashMap。
![image](https://520li.oss-cn-hangzhou.aliyuncs.com/img/clipboard-1590157157001.png)
![image](https://520li.oss-cn-hangzhou.aliyuncs.com/img/clipboard-1590157168942.png)

> 在 Java8 中， 当链表中的元素超过了**8**个以后，会将链表转换为红黑树

### 常见面试题
- 为什么**负载因子**是0.75
>负载因子0.75是表示Hsah表中元素的填满的程度。**加载因子越大,填满的元素越多,空间利用率越高，但冲突的机会加大了**。反之,加载因子越小,填满的元素越少,冲突的机会减小,但空间浪费多了。冲突的机会越大,则查找的成本越高。反之,查找的成本越小。因此,必须在 "**冲突的机会**"与"**空间利用率**"之间寻找一种平衡与折衷
- 为什么HashMap的长度一定是**2的幂次方**
>是为了减少**hash碰撞**，**存取高效**（在取模时可以直接使用位移运算，比求余效率高），尽量使hash算法的结果均匀分布（因为2的N次方实际就是1后面N个0，length-1就是n个1，在取模时会减少碰撞的概率）
- 为什么要使用**红黑树**
>如果Hash冲突比较严重，则会导致链表的长度很长，最差的情况下时间复杂度会变成**O(N)**，严重影响检索效率，而红黑树在查找、插入、删除的时间复杂度比较稳定，都是O（log2N）（对数型）。在链表的长度超过阈值（8）时就会把链表转成红黑树。
- 为什么初始化时尽量**指定容量**
>初始容量是16，当size达到16*0.75时就会触发扩容（在1.7中，如果数组下标对应的值为null，则不会扩容），而扩容的开销是比较大的，需要创建一个新的table（原容量的2倍）。
- 为什么在1.8以前存在**死循环**的风险
>在1.8以前链表每增加值时会放到链表的头部，在扩容时又从头部开始循环插入到新的table，就会导致链表的顺序颠倒，在多线程情况下会导致next指向变成死循环。在1.8修复了这个问题，新的值放到链表的尾部，会保障顺序的一致性。
- HashMap**线程不安全**，会导致出现什么问题
>1->**数据丢失**的风险。在多线程情况下，如果同时持有同一个节点，同时修改next，就会导致next被覆盖，也就导致数据丢失。
>
>2->**size不正确**。transient int size，既不是volatile（保障可见性、有序性），又不是AtomicInteger的原子性类，在多线程情况因为原子性、可见性等问题导致size**小于实际值**。
- 为什么不直接将key作为哈希值而是与**高16位做异或运算**？
>因为数组位置的确定用的是**与运算**，仅仅低位有效，设计者将key的哈希值与高16为做异或运算使得在做&运算确定数组的插入位置时，此时的低位实际是**高位与低位**的结合，**增加了随机性**，减少了哈希碰撞的次数。 

## ConcurrentHashMap
### 实现原理分析
ConcurrentHashMap 和 HashMap思路是差不多的，但是支持并发操作，使用**分段锁**（segment，继承ReentrantLock）技术。将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。在JDK1.7中默认的segment是**16**。
![image](https://520li.oss-cn-hangzhou.aliyuncs.com/img/clipboard-1590157185358.png)

JDK1.8的实现已经抛弃了Segment分段锁机制，利用**CAS+Synchronized**来保证并发更新的安全。数据结构采用：**数组+链表+红黑树**。
![image](https://520li.oss-cn-hangzhou.aliyuncs.com/img/clipboard-1590157205467.png)

### 常见面试题
- ConcurrentHashMap使用什么技术来**保证线程安全**？
>jdk1.7：Segment+HashEntry来进行实现的；
>
>jdk1.8：放弃了Segment臃肿的设计，采用Node+CAS+Synchronized来保证线程安全；
- ConcurrentHashMap的g**et方法是否要加锁**，为什么？
>不需要，get方法采用了unsafe方法（使用**volatile**保障可见性），来保证线程安全。
- ConcurrentHashMap迭代器是**强一致性还是弱一致性**？HashMap呢？
>**弱一致性，hashmap是强一致性**。
>
>ConcurrentHashMap可以支持在迭代过程中，向map添加新元素，而HashMap则抛出了ConcurrentModificationException（fail-fast），
>因为HashMap包含一个修改计数器，当你调用他的next()方法来获取下一个元素时，迭代器将会用到这个计数器。
- ConcurrentHashMap在**1.7和1.8**的区别
>jdk1.8的实现降低锁的粒度，jdk1.7锁的粒度是基于Segment的，包含多个HashEntry，而jdk1.8锁的粒度就是Node。
>
>数据结构：jdk1.7 Segment+HashEntry；jdk1.8 数组+链表+红黑树+CAS+synchronized
- **扩容机制**是怎样的？
>在JDK1.7中需要等扩容完成才能读写操作。在1.8时增加了**多线程扩容机制**，增加了ForwardingNode（标识扩容状态，在原table上），多线程扩容机制：
>
>1）在get时，如果节点有数据，则直接返回数据，如果节点无数据，且被设置fwd节点，则**当前get线程参与扩容**
>
>2）在put/remove时，如果此时链表**已迁移完成**（fwd节点），此时会参与扩容，如果扩容没有完成，则当前链表的头部会被锁住，所以**写线程被堵塞，直到扩容完成**


## HashMap源码解析（JDK 1.8）
### 全局变量
```java
// 初始化默认的容量 ，必须是2的指数幂。
static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16

// 最大的容量值。
static final int MAXIMUM_CAPACITY = 1 << 30;

// 默认的负载因子 当数量达到 容量 * 负载因子 时， 则扩充当前HashMap的容量 为当前的2倍。
static final float DEFAULT_LOAD_FACTOR = 0.75f;

// 链表转化为树的阈值
static final int TREEIFY_THRESHOLD = 8;

// 树转化为链表的阈值
static final int UNTREEIFY_THRESHOLD = 6;

// 桶（bin）中的数据要采用红黑树结构进行存储时，整个Table的最小容量
static final int MIN_TREEIFY_CAPACITY = 64;
```

### 构造函数
```java
public HashMap() {
    this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted
}
public HashMap(int initialCapacity) {
    this(initialCapacity, DEFAULT_LOAD_FACTOR);
}
public HashMap(int initialCapacity, float loadFactor) {
    if (initialCapacity < 0)
        throw new IllegalArgumentException("Illegal initial capacity: " +
                initialCapacity);
    if (initialCapacity > MAXIMUM_CAPACITY)
        initialCapacity = MAXIMUM_CAPACITY;
    if (loadFactor <= 0 || Float.isNaN(loadFactor))
        throw new IllegalArgumentException("Illegal load factor: " +
                loadFactor);
    this.loadFactor = loadFactor;
    this.threshold = tableSizeFor(initialCapacity);
}
public HashMap(Map<? extends K, ? extends V> m) {
    this.loadFactor = DEFAULT_LOAD_FACTOR;
    putMapEntries(m, false);
}
```
- 如果传入初始化容量（initialCapacity），则会通过通过tableSizeFor(int cap)对传入的 容量 取 大于等于 该值 最小的**2的指数幂**。
```java
static final int tableSizeFor(int cap) {
    int n = cap - 1;
    n |= n >>> 1;
    n |= n >>> 2;
    n |= n >>> 4;
    n |= n >>> 8;
    n |= n >>> 16;
    return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
}
```

### put(K key, V value) 存数据
分为以下三种情况：
- 插入位置无数据，直接存入当前的key在table的位置
- 插入位置有数据，但是较少且符合链表结构存储的条件，那么以链表操作存入
- 插入位置有数据，但是以树结构进行存储，那么以树的相关操作进行存入

源码解析：
- (1.0) 通过 key.hashCode() ^ (key.hashCode() >>> 16) 获取 key 的 hash 值。
- (2.0) 如果当前的table 为 空 或者 长度为0 则做一次扩容操作。
- (3.0) 通过 (n-1) ^ hash 获取 key 所在 table 的位置，如果当前的 node=null || size = 0，则把当前的数据构建一个新的 node 存在当前位置，否则看(4.0) 。
- (4.0) 如果当前 node 的 hash 和 key 和传入的 hash 和 key 相同，则通过(7.0) 更新 node。
- (5.0) 如果当前的 node 已经变为TreeNode，则执行 TreeNode 的 插入操作，后面介绍 TreeNode再详细介绍。
- (6.0) 遍历当前 node 链表，如果找到满足(4.0)的条件的 node，则通过(7.0) 更新 node，否则新建一个 node 添加到当前的链表最后，并判断(6.1)，再执行(8.0)。
- (6.1) 如果当前的node的数据已达到 TREEIFY_THRESHOLD - 1， 则通过treeifyBin(tab, hash)转化为树。
- (7.0) 更新当前的node的值为 传入的 value，并返回之前的oldValue。
- (8.0) 判断是否需要做扩容操作。
```java
public V put(K key, V value) {
    return putVal(hash(key), key, value, false, true);
}
static final int hash(Object key) {
    // 1.0
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
               boolean evict) {
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    if ((tab = table) == null || (n = tab.length) == 0)
        // 2.0
        n = (tab = resize()).length;
    if ((p = tab[i = (n - 1) & hash]) == null)
        //3.0
        tab[i] = newNode(hash, key, value, null);
    else {
        Node<K,V> e; K k;
        if (p.hash == hash &&
                ((k = p.key) == key || (key != null && key.equals(k))))
            //4.0
            e = p;
        else if (p instanceof TreeNode)
            //5.0
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
        else {
            //6.0
            for (int binCount = 0; ; ++binCount) {
                if ((e = p.next) == null) {
                    p.next = newNode(hash, key, value, null);
                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        //6.1
                        treeifyBin(tab, hash);
                    break;
                }
                if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                    break;
                p = e;
            }
        }
        //7.0
        if (e != null) { // existing mapping for key
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);
            return oldValue;
        }
    }
    //8.0
    ++modCount;
    if (++size > threshold)
        resize();
    afterNodeInsertion(evict);
    return null;
}
```

### resize() 扩容
- (1.0) 如果当前的容量 已经达到 最大容量MAXIMUM_CAPACITY(1<<30)了，就不再扩容了，直接返回当前的table。
- (2.0) 如果当前的容量>= DEFAULT_INITIAL_CAPACITY(16)，并且 容量 扩大一倍之后还< MAXIMUM_CAPACITY，则容量扩大一倍，得到newCap。
- (3.0) 如果之前没有数据，则赋值 newCap 为默认的容量(16) 以及 默认的扩容阈值(16 * 0.75)。
- (4.0) 如果 扩容阈值 还为0，则更新当前的 容量 和 负载因子 计算 扩容阈值(threshold)。
- (5.0) 然后构建一个容量为 newCap的 新 table，把之前的数据存进去。
```java
final Node<K,V>[] resize() {
    Node<K,V>[] oldTab = table;
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    int oldThr = threshold;
    int newCap, newThr = 0;
    if (oldCap > 0) {
        if (oldCap >= MAXIMUM_CAPACITY) {
            //1.0
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                oldCap >= DEFAULT_INITIAL_CAPACITY)
            //2.0
            newThr = oldThr << 1; // double threshold
    }
    else if (oldThr > 0) // initial capacity was placed in threshold
        newCap = oldThr;
    else {               // zero initial threshold signifies using defaults
        //3.0
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }
    if (newThr == 0) {
        //4.0
        float ft = (float)newCap * loadFactor;
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                (int)ft : Integer.MAX_VALUE);
    }
    threshold = newThr;
    //5.0
    @SuppressWarnings({"rawtypes","unchecked"})
    Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
    table = newTab;
    if (oldTab != null) {
        for (int j = 0; j < oldCap; ++j) {
            Node<K,V> e;
            if ((e = oldTab[j]) != null) {
                oldTab[j] = null;
                if (e.next == null)
                    newTab[e.hash & (newCap - 1)] = e;
                else if (e instanceof TreeNode)
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                else { // preserve order
                    Node<K,V> loHead = null, loTail = null;
                    Node<K,V> hiHead = null, hiTail = null;
                    Node<K,V> next;
                    do {
                        next = e.next;
                        if ((e.hash & oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        else {
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
}
```

### get(Object key) 取数据
- 如果当前的 tab 没数据，或者没有对应的key 则返回null.
- 否则先校验第一个 node，再看是 通过 getTreeNode(int h, Object k)去树中找 还是 遍历当前的 链表。
```java
public V get(Object key) {
    Node<K,V> e;
    return (e = getNode(hash(key), key)) == null ? null : e.value;
}

final Node<K,V> getNode(int hash, Object key) {
    Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
    if ((tab = table) != null && (n = tab.length) > 0 &&
            (first = tab[(n - 1) & hash]) != null) {
        if (first.hash == hash && // always check first node
                ((k = first.key) == key || (key != null && key.equals(k))))
            return first;
        if ((e = first.next) != null) {
            if (first instanceof TreeNode)
                return ((TreeNode<K,V>)first).getTreeNode(hash, key);
            do {
                if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    return null;
}
```

### remove(Object key) 删除数据
- (1.0) 通过 tab != null && (n = tab.length) > 0 && (p = tab[index = (n - 1) & hash]) != null校验table不为空，并且 在table上对应索引的值不为空。
- (2.0) 判断链表 key 对应位置的第一个是不是对应的key，是的话就赋值给 node。
- (3.0) 判断当前是否已经树化，是的话，则通过getTreeNode去获取对应的节点。
- (4.0) 是链表的话，就遍历链表找到对应的key的节点，赋值给 ·node`。
- (5.0) 判断node是否为空，并且对应的值是否相等。(5.1)树化则调用removeTreeNode移除树的节点；(5.2)如果为key在当前tab的索引位置，直接覆盖；(5.3) 否则通过p.next = node.next 直接移除node.
- (6.0)  afterNodeRemoval方法默认是空实现。
```java
public V remove(Object key) {
    Node<K,V> e;
    return (e = removeNode(hash(key), key, null, false, true)) == null ?
            null : e.value;
}
final Node<K,V> removeNode(int hash, Object key, Object value,
                           boolean matchValue, boolean movable) {
    Node<K,V>[] tab; Node<K,V> p; int n, index;
    if ((tab = table) != null && (n = tab.length) > 0 &&
            (p = tab[index = (n - 1) & hash]) != null) { //1.0
        Node<K,V> node = null, e; K k; V v;
        if (p.hash == hash &&
                ((k = p.key) == key || (key != null && key.equals(k))))
            node = p;//2.0
        else if ((e = p.next) != null) {
            if (p instanceof TreeNode)//3.0
                node = ((TreeNode<K,V>)p).getTreeNode(hash, key);
            else {//4.0
                do {
                    if (e.hash == hash &&
                            ((k = e.key) == key ||
                                    (key != null && key.equals(k)))) {
                        node = e;
                        break;
                    }
                    p = e;
                } while ((e = e.next) != null);
            }
        }
        if (node != null && (!matchValue || (v = node.value) == value ||
                (value != null && value.equals(v)))) { //5.0
            if (node instanceof TreeNode)//5.1
                ((TreeNode<K,V>)node).removeTreeNode(this, tab, movable);
            else if (node == p)//5.2
                tab[index] = node.next;
            else//5.3
                p.next = node.next;
            ++modCount;
            --size;
            afterNodeRemoval(node);//6.0
            return node;
        }
    }
    return null;
}
```
```java
// Callbacks to allow LinkedHashMap post-actions
void afterNodeAccess(Node<K,V> p) { }
void afterNodeInsertion(boolean evict) { }
void afterNodeRemoval(Node<K,V> p) { }
```

### treeifyBin(Node<K,V>[] tab, int hash) 链表树化
- (1.0) 没有达到树化的最小数量MIN_TREEIFY_CAPACITY，则进行扩容操作。
- (2.0) 满足树化的条件，则把链表的每个节点都转化为 TreeNode。
- (3.0) 通过TreeNode的treeify(Node<K,V>[] tab)方法构建树。
```java
final void treeifyBin(Node<K,V>[] tab, int hash) {
    int n, index; Node<K,V> e;
    if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)//1.0
        resize();
    else if ((e = tab[index = (n - 1) & hash]) != null) {
        TreeNode<K,V> hd = null, tl = null;
        do {//2.0
            TreeNode<K,V> p = replacementTreeNode(e, null);
            if (tl == null)
                hd = p;
            else {
                p.prev = tl;
                tl.next = p;
            }
            tl = p;
        } while ((e = e.next) != null);
        if ((tab[index] = hd) != null)
            hd.treeify(tab);//3.0
    }
}
```

## ConcurrentHashMap源码解析（JDK 1.8）
### 全局变量
```java
// 能转化为数组的最大长度 231 -1 - 8
static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;

// 默认的并发等级
private static final int DEFAULT_CONCURRENCY_LEVEL = 16;

// 最小迁移步幅，只在transfer方法中用到
private static final int MIN_TRANSFER_STRIDE = 16;

// 用于记录sizeCtl中的 resize stamp
private static final int RESIZE_STAMP_BITS = 16;

// 参与resize的最大线程数，如果是默认值，那么位 (1 << (32-16)) - 1 = 32 - 1 = 31
private static final int MAX_RESIZERS = (1 << (32 - RESIZE_STAMP_BITS)) - 1;

// 用于记录sizeCtl中的 resize stamp偏移位
private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;

// 哈希散列的值
static final int HASH_BITS = 0x7fffffff;

/** ====== 以下常量与HashMap一致 ====== **/
//链表树化的阈值
static final int TREEIFY_THRESHOLD = 8;
//树边链表的阈值
static final int UNTREEIFY_THRESHOLD = 6;
//树化时的最小容量
static final int MIN_TREEIFY_CAPACITY = 64;
//最大容量
private static final int MAXIMUM_CAPACITY = 1 << 30;
//默认容量
private static final int DEFAULT_CAPACITY = 16;
//负载因子
private static final float LOAD_FACTOR = 0.75f;
```

### spread(int h) 散列计算
作用同HashMap的 hash方法
```java
static final int spread(int h) {
    return (h ^ (h >>> 16)) & HASH_BITS;
}
```

### tableSizeFor(int c) 根据传入的值计算容量
计算大于等于传入数的最小的 2的N次方 的值
```java
private static final int tableSizeFor(int c) {
    int n = c - 1;
    n |= n >>> 1;
    n |= n >>> 2;
    n |= n >>> 4;
    n |= n >>> 8;
    n |= n >>> 16;
    return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
}
```

### size() 计算大小
对CounterCell数组中每一项求和。
```java
/**
 * Table of counter cells. When non-null, size is a power of 2.
 */
private transient volatile CounterCell[] counterCells;
static final class CounterCell {
    volatile long value;
    CounterCell(long x) { value = x; }
}
public int size() {
    long n = sumCount();
    return ((n < 0L) ? 0 :
            (n > (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE :
                    (int)n);
}
final long sumCount() {
    CounterCell[] as = counterCells; CounterCell a;
    long sum = baseCount;
    if (as != null) {
        for (int i = 0; i < as.length; ++i) {
            if ((a = as[i]) != null)
                sum += a.value;
        }
    }
    return sum;
}
```

### initTable() 初始化table
- (1.0) 当sizeCtl < 0时，则会让出CPU的时间，等待下次重试。
- (2.0) 当sizeCtl >= 0时，则通过 CAS 原子操作将 sizeCtl 设置为 -1。
- (3.0) 设置成功之后，如果table为空，则初始化对应长度的 Node数组。并将 当前容量能保存的最大数量(n * LOAD_FACTOR)赋值给sizeCtl
```java
/**
 * 初始化数组table，
 * 如果sizeCtl小于0，说明别的数组正在进行初始化，则让出执行权
 * 如果sizeCtl大于0的话，则初始化一个大小为sizeCtl的数组
 * 否则的话初始化一个默认大小(16)的数组
 * 然后设置sizeCtl的值为数组长度的3/4
 */
private final Node<K,V>[] initTable() {
    Node<K,V>[] tab; int sc;
    while ((tab = table) == null || tab.length == 0) {    //第一次put的时候，table还没被初始化，进入while
        if ((sc = sizeCtl) < 0)                            //sizeCtl初始值为0，当小于0的时候表示在别的线程在初始化表或扩展表
            Thread.yield(); // lost initialization race; just spin
        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {    //SIZECTL：表示当前对象的内存偏移量，sc表示期望值，-1表示要替换的值，设定为-1表示要初始化表了
            try {
                if ((tab = table) == null || tab.length == 0) {
                    int n = (sc > 0) ? sc : DEFAULT_CAPACITY;        //指定了大小的时候就创建指定大小的Node数组，否则创建指定大小(16)的Node数组
                    @SuppressWarnings("unchecked")
                    Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                    table = tab = nt;
                    sc = n - (n >>> 2);
                }
            } finally {
                sizeCtl = sc;            //初始化后，sizeCtl长度为数组长度的3/4
            }
            break;
        }
    }
    return tab;
}
```

### put(K key, V value) 存数据
![image](https://520li.oss-cn-hangzhou.aliyuncs.com/img/clipboard-1590157255606.png)
```java
    /*
     *  单纯的额调用putVal方法，并且putVal的第三个参数设置为false
     *  当设置为false的时候表示这个value一定会设置
     *  true的时候，只有当这个key的value为空的时候才会设置
     */
    public V put(K key, V value) {
        return putVal(key, value, false);
    }

	/*
     * 当添加一对键值对的时候，首先会去判断保存这些键值对的数组是不是初始化了，
     * 如果没有的话就初始化数组
     *  然后通过计算hash值来确定放在数组的哪个位置
     * 如果这个位置为空则直接添加，如果不为空的话，则取出这个节点来
     * 如果取出来的节点的hash值是MOVED(-1)的话，则表示当前正在对这个数组进行扩容，复制到新的数组，则当前线程也去帮助复制
     * 最后一种情况就是，如果这个节点，不为空，也不在扩容，则通过synchronized来加锁，进行添加操作
     *    然后判断当前取出的节点位置存放的是链表还是树
     *    如果是链表的话，则遍历整个链表，直到取出来的节点的key来个要放的key进行比较，如果key相等，并且key的hash值也相等的话，
     *          则说明是同一个key，则覆盖掉value，否则的话则添加到链表的末尾
     *    如果是树的话，则调用putTreeVal方法把这个元素添加到树中去
     *  最后在添加完成之后，会判断在该节点处共有多少个节点（注意是添加前的个数），如果达到8个以上了的话，
     *  则调用treeifyBin方法来尝试将处的链表转为树，或者扩容数组
     */
    final V putVal(K key, V value, boolean onlyIfAbsent) {
        if (key == null || value == null) throw new NullPointerException();//K,V都不能为空，否则的话跑出异常
        int hash = spread(key.hashCode());    //取得key的hash值
        int binCount = 0;    //用来计算在这个节点总共有多少个元素，用来控制扩容或者转移为树
        for (Node<K,V>[] tab = table;;) {    //
            Node<K,V> f; int n, i, fh;
            if (tab == null || (n = tab.length) == 0)    
                tab = initTable();    //第一次put的时候table没有初始化，则初始化table
            else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {    //通过哈希计算出一个表中的位置因为n是数组的长度，所以(n-1)&hash肯定不会出现数组越界
                if (casTabAt(tab, i, null,        //如果这个位置没有元素的话，则通过cas的方式尝试添加，注意这个时候是没有加锁的
                             new Node<K,V>(hash, key, value, null)))        //创建一个Node添加到数组中区，null表示的是下一个节点为空
                    break;                   // no lock when adding to empty bin
            }
            /*
             * 如果检测到某个节点的hash值是MOVED，则表示正在进行数组扩张的数据复制阶段，
             * 则当前线程也会参与去复制，通过允许多线程复制的功能，一次来减少数组的复制所带来的性能损失
             */
            else if ((fh = f.hash) == MOVED)    
                tab = helpTransfer(tab, f);
            else {
                /*
                 * 如果在这个位置有元素的话，就采用synchronized的方式加锁，
                 *     如果是链表的话(hash大于0)，就对这个链表的所有元素进行遍历，
                 *         如果找到了key和key的hash值都一样的节点，则把它的值替换到
                 *         如果没找到的话，则添加在链表的最后面
                 *  否则，是树的话，则调用putTreeVal方法添加到树中去
                 *  
                 *  在添加完之后，会对该节点上关联的的数目进行判断，
                 *  如果在8个以上的话，则会调用treeifyBin方法，来尝试转化为树，或者是扩容
                 */
                V oldVal = null;
                synchronized (f) {
                    if (tabAt(tab, i) == f) {        //再次取出要存储的位置的元素，跟前面取出来的比较
                        if (fh >= 0) {                //取出来的元素的hash值大于0，当转换为树之后，hash值为-2
                            binCount = 1;            
                            for (Node<K,V> e = f;; ++binCount) {    //遍历这个链表
                                K ek;
                                if (e.hash == hash &&        //要存的元素的hash，key跟要存储的位置的节点的相同的时候，替换掉该节点的value即可
                                    ((ek = e.key) == key ||
                                     (ek != null && key.equals(ek)))) {
                                    oldVal = e.val;
                                    if (!onlyIfAbsent)        //当使用putIfAbsent的时候，只有在这个key没有设置值得时候才设置
                                        e.val = value;
                                    break;
                                }
                                Node<K,V> pred = e;
                                if ((e = e.next) == null) {    //如果不是同样的hash，同样的key的时候，则判断该节点的下一个节点是否为空，
                                    pred.next = new Node<K,V>(hash, key,        //为空的话把这个要加入的节点设置为当前节点的下一个节点
                                                              value, null);
                                    break;
                                }
                            }
                        }
                        else if (f instanceof TreeBin) {    //表示已经转化成红黑树类型了
                            Node<K,V> p;
                            binCount = 2;
                            if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,    //调用putTreeVal方法，将该元素添加到树中去
                                                           value)) != null) {
                                oldVal = p.val;
                                if (!onlyIfAbsent)
                                    p.val = value;
                            }
                        }
                    }
                }
                if (binCount != 0) {
                    if (binCount >= TREEIFY_THRESHOLD)    //当在同一个节点的数目达到8个的时候，则扩张数组或将给节点的数据转为tree
                        treeifyBin(tab, i);    
                    if (oldVal != null)
                        return oldVal;
                    break;
                }
            }
        }
        addCount(1L, binCount);    //计数
        return null;
    }
```

### get(Object key) 取数据
```java
	/*
     * 相比put方法，get就很单纯了，支持并发操作，
     * 当key为null的时候回抛出NullPointerException的异常
     * get操作通过首先计算key的hash值来确定该元素放在数组的哪个位置
     * 然后遍历该位置的所有节点
     * 如果不存在的话返回null
     */
    public V get(Object key) {
        Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;
        int h = spread(key.hashCode());
        if ((tab = table) != null && (n = tab.length) > 0 &&
            (e = tabAt(tab, (n - 1) & h)) != null) {
            if ((eh = e.hash) == h) {
                if ((ek = e.key) == key || (ek != null && key.equals(ek)))
                    return e.val;
            }
            else if (eh < 0)
                return (p = e.find(h, key)) != null ? p.val : null;
            while ((e = e.next) != null) {
                if (e.hash == h &&
                    ((ek = e.key) == key || (ek != null && key.equals(ek))))
                    return e.val;
            }
        }
        return null;
    }
```

### transfer 扩容

```java
	/**
     * Moves and/or copies the nodes in each bin to new table. See
     * above for explanation.
     * 把数组中的节点复制到新的数组的相同位置，或者移动到扩张部分的相同位置
     * 在这里首先会计算一个步长，表示一个线程处理的数组长度，用来控制对CPU的使用，
     * 每个CPU最少处理16个长度的数组元素,也就是说，如果一个数组的长度只有16，那只有一个线程会对其进行扩容的复制移动操作
     * 扩容的时候会一直遍历，直到复制完所有节点，没处理一个节点的时候会在链表的头部设置一个fwd节点，这样其他线程就会跳过他，
     * 复制后在新数组中的链表不是绝对的反序的
     */
    private final void transfer(Node<K,V>[] tab, Node<K,V>[] nextTab) {
        int n = tab.length, stride;
        if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) < MIN_TRANSFER_STRIDE)    //MIN_TRANSFER_STRIDE 用来控制不要占用太多CPU
            stride = MIN_TRANSFER_STRIDE; // subdivide range    //MIN_TRANSFER_STRIDE=16
        /*
         * 如果复制的目标nextTab为null的话，则初始化一个table两倍长的nextTab
         * 此时nextTable被设置值了(在初始情况下是为null的)
         * 因为如果有一个线程开始了表的扩张的时候，其他线程也会进来帮忙扩张，
         * 而只是第一个开始扩张的线程需要初始化下目标数组
         */
        if (nextTab == null) {            // initiating
            try {
                @SuppressWarnings("unchecked")
                Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n << 1];
                nextTab = nt;
            } catch (Throwable ex) {      // try to cope with OOME
                sizeCtl = Integer.MAX_VALUE;
                return;
            }
            nextTable = nextTab;
            transferIndex = n;
        }
        int nextn = nextTab.length;
        /*
         * 创建一个fwd节点，这个是用来控制并发的，当一个节点为空或已经被转移之后，就设置为fwd节点
         * 这是一个空的标志节点
         */
        ForwardingNode<K,V> fwd = new ForwardingNode<K,V>(nextTab);
        boolean advance = true;    //是否继续向前查找的标志位
        boolean finishing = false; // to ensure sweep(清扫) before committing nextTab,在完成之前重新在扫描一遍数组，看看有没完成的没
        for (int i = 0, bound = 0;;) {
            Node<K,V> f; int fh;
            while (advance) {
                int nextIndex, nextBound;
                if (--i >= bound || finishing) {
                    advance = false;
                }
                else if ((nextIndex = transferIndex) <= 0) {
                    i = -1;
                    advance = false;
                }
                else if (U.compareAndSwapInt
                         (this, TRANSFERINDEX, nextIndex,
                          nextBound = (nextIndex > stride ?
                                       nextIndex - stride : 0))) {
                    bound = nextBound;
                    i = nextIndex - 1;
                    advance = false;
                }
            }
            if (i < 0 || i >= n || i + n >= nextn) {
                int sc;
                if (finishing) {        //已经完成转移
                    nextTable = null;
                    table = nextTab;
                    sizeCtl = (n << 1) - (n >>> 1);    //设置sizeCtl为扩容后的0.75
                    return;
                }
                if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {
                    if ((sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT) {
                            return;
                    }
                    finishing = advance = true;
                    i = n; // recheck before commit
                }
            }
            else if ((f = tabAt(tab, i)) == null)            //数组中把null的元素设置为ForwardingNode节点(hash值为MOVED[-1])
                advance = casTabAt(tab, i, null, fwd);
            else if ((fh = f.hash) == MOVED)
                advance = true; // already processed
            else {
                synchronized (f) {                //加锁操作
                    if (tabAt(tab, i) == f) {
                        Node<K,V> ln, hn;
                        if (fh >= 0) {        //该节点的hash值大于等于0，说明是一个Node节点
                                /*
                                 * 因为n的值为数组的长度，且是power(2,x)的，所以，在&操作的结果只可能是0或者n
                                 * 根据这个规则
                                 *         0-->  放在新表的相同位置
                                 *         n-->  放在新表的（n+原来位置）
                                 */
                            int runBit = fh & n; 
                            Node<K,V> lastRun = f;
                            /*
                             * lastRun 表示的是需要复制的最后一个节点
                             * 每当新节点的hash&n -> b 发生变化的时候，就把runBit设置为这个结果b
                             * 这样for循环之后，runBit的值就是最后不变的hash&n的值
                             * 而lastRun的值就是最后一次导致hash&n 发生变化的节点(假设为p节点)
                             * 为什么要这么做呢？因为p节点后面的节点的hash&n 值跟p节点是一样的，
                             * 所以在复制到新的table的时候，它肯定还是跟p节点在同一个位置
                             * 在复制完p节点之后，p节点的next节点还是指向它原来的节点，就不需要进行复制了，自己就被带过去了
                             * 这也就导致了一个问题就是复制后的链表的顺序并不一定是原来的倒序
                             */
                            for (Node<K,V> p = f.next; p != null; p = p.next) {
                                int b = p.hash & n;    //n的值为扩张前的数组的长度
                                if (b != runBit) {
                                    runBit = b;
                                    lastRun = p;
                                }
                            }
                            if (runBit == 0) {
                                ln = lastRun;
                                hn = null;
                            }
                            else {
                                hn = lastRun;
                                ln = null;
                            }
                            /*
                             * 构造两个链表，顺序大部分和原来是反的
                             * 分别放到原来的位置和新增加的长度的相同位置(i/n+i)
                             */
                            for (Node<K,V> p = f; p != lastRun; p = p.next) {
                                int ph = p.hash; K pk = p.key; V pv = p.val;
                                if ((ph & n) == 0)
                                        /*
                                         * 假设runBit的值为0，
                                         * 则第一次进入这个设置的时候相当于把旧的序列的最后一次发生hash变化的节点(该节点后面可能还有hash计算后同为0的节点)设置到旧的table的第一个hash计算后为0的节点下一个节点
                                         * 并且把自己返回，然后在下次进来的时候把它自己设置为后面节点的下一个节点
                                         */
                                    ln = new Node<K,V>(ph, pk, pv, ln);
                                else
                                        /*
                                         * 假设runBit的值不为0，
                                         * 则第一次进入这个设置的时候相当于把旧的序列的最后一次发生hash变化的节点(该节点后面可能还有hash计算后同不为0的节点)设置到旧的table的第一个hash计算后不为0的节点下一个节点
                                         * 并且把自己返回，然后在下次进来的时候把它自己设置为后面节点的下一个节点
                                         */
                                    hn = new Node<K,V>(ph, pk, pv, hn);    
                            }
                            setTabAt(nextTab, i, ln);    
                            setTabAt(nextTab, i + n, hn);
                            setTabAt(tab, i, fwd);
                            advance = true;
                        }
                        else if (f instanceof TreeBin) {    //否则的话是一个树节点
                            TreeBin<K,V> t = (TreeBin<K,V>)f;
                            TreeNode<K,V> lo = null, loTail = null;
                            TreeNode<K,V> hi = null, hiTail = null;
                            int lc = 0, hc = 0;
                            for (Node<K,V> e = t.first; e != null; e = e.next) {
                                int h = e.hash;
                                TreeNode<K,V> p = new TreeNode<K,V>
                                    (h, e.key, e.val, null, null);
                                if ((h & n) == 0) {
                                    if ((p.prev = loTail) == null)
                                        lo = p;
                                    else
                                        loTail.next = p;
                                    loTail = p;
                                    ++lc;
                                }
                                else {
                                    if ((p.prev = hiTail) == null)
                                        hi = p;
                                    else
                                        hiTail.next = p;
                                    hiTail = p;
                                    ++hc;
                                }
                            }
                            /*
                             * 在复制完树节点之后，判断该节点处构成的树还有几个节点，
                             * 如果≤6个的话，就转回为一个链表
                             */
                            ln = (lc <= UNTREEIFY_THRESHOLD) ? untreeify(lo) :
                                (hc != 0) ? new TreeBin<K,V>(lo) : t;
                            hn = (hc <= UNTREEIFY_THRESHOLD) ? untreeify(hi) :
                                (lc != 0) ? new TreeBin<K,V>(hi) : t;
                            setTabAt(nextTab, i, ln);
                            setTabAt(nextTab, i + n, hn);
                            setTabAt(tab, i, fwd);
                            advance = true;
                        }
                    }
                }
            }
        }
    }
```



### remove(Object key) 移除数据

![image](https://520li.oss-cn-hangzhou.aliyuncs.com/img/clipboard-1590157271566.png)
```java
public V remove(Object key) {
    return replaceNode(key, null, null);
}
final V replaceNode(Object key, V value, Object cv) {
    int hash = spread(key.hashCode());
    for (Node<K, V>[] tab = table; ; ) {
        Node<K, V> f;
        int n, i, fh;
        if (tab == null || (n = tab.length) == 0 ||
                (f = tabAt(tab, i = (n - 1) & hash)) == null)
            break;
        else if ((fh = f.hash) == MOVED)
            tab = helpTransfer(tab, f);
        else {
            V oldVal = null;
            boolean validated = false;
            synchronized (f) {
                if (tabAt(tab, i) == f) {
                    if (fh >= 0) {
                        validated = true;
                        for (Node<K, V> e = f, pred = null; ; ) {
                            K ek;
                            if (e.hash == hash &&
                                    ((ek = e.key) == key ||
                                            (ek != null && key.equals(ek)))) {
                                V ev = e.val;
                                if (cv == null || cv == ev ||
                                        (ev != null && cv.equals(ev))) {
                                    oldVal = ev;
                                    if (value != null)
                                        e.val = value;
                                    else if (pred != null)
                                        pred.next = e.next;
                                    else
                                        setTabAt(tab, i, e.next);
                                }
                                break;
                            }
                            pred = e;
                            if ((e = e.next) == null)
                                break;
                        }
                    } else if (f instanceof TreeBin) {
                        validated = true;
                        TreeBin<K, V> t = (TreeBin<K, V>) f;
                        TreeNode<K, V> r, p;
                        if ((r = t.root) != null &&
                                (p = r.findTreeNode(hash, key, null)) != null) {
                            V pv = p.val;
                            if (cv == null || cv == pv ||
                                    (pv != null && cv.equals(pv))) {
                                oldVal = pv;
                                if (value != null)
                                    p.val = value;
                                else if (t.removeTreeNode(p))
                                    setTabAt(tab, i, untreeify(t.first));
                            }
                        }
                    } else if (f instanceof ReservationNode)
                        throw new IllegalStateException("Recursive update");
                }
            }
            if (validated) {
                if (oldVal != null) {
                    if (value == null)
                        addCount(-1L, -1);
                    return oldVal;
                }
                break;
            }
        }
    }
    return null;
}
```



## LinkedHashMap源码解析（JDK 1.8）

### 全局变量
```java
// 双向链表的头节点
transient LinkedHashMapEntry<K,V> head;

// 双向链表的尾节点
transient LinkedHashMapEntry<K,V> tail;

// false：按插入顺序排序；true：按访问顺序排序
final boolean accessOrder;
```
LinkedHashMapEntry在HashMap.Node的基础上添加了**before和after**节点在实现双向链表。
```java
static class LinkedHashMapEntry<K,V> extends HashMap.Node<K,V> {
    LinkedHashMapEntry<K,V> before, after;
    LinkedHashMapEntry(int hash, K key, V value, Node<K,V> next) {
        super(hash, key, value, next);
    }
}
```

### 构造函数
相比HashMap来说，只是添加了accessOrder默认为false，以及可以设置accessOrder的构造函数。
```java
public LinkedHashMap() {
    super();
    accessOrder = false;
}
public LinkedHashMap(int initialCapacity) {
    super(initialCapacity);
    accessOrder = false;
}
public LinkedHashMap(int initialCapacity, float loadFactor) {
    super(initialCapacity, loadFactor);
    accessOrder = false;
}
public LinkedHashMap(Map<? extends K, ? extends V> m) {
    super();
    accessOrder = false;
    putMapEntries(m, false);
}
public LinkedHashMap(int initialCapacity, float loadFactor, 
                     boolean accessOrder) {
    super(initialCapacity, loadFactor);
    this.accessOrder = accessOrder;
}
```

### afterNodeAccess(Node<K,V> p)数据访问之后
```java
void afterNodeAccess(Node<K, V> e) {
    LinkedHashMapEntry<K, V> last;
    if (accessOrder && (last = tail) != e) {
        LinkedHashMapEntry<K, V> p =
                (LinkedHashMapEntry<K, V>) e, b = p.before, a = p.after;
        p.after = null;
        if (b == null)
            head = a;
        else
            b.after = a;
        if (a != null)
            a.before = b;
        else
            last = b;
        if (last == null)
            head = p;
        else {
            p.before = last;
            last.after = p;
        }
        tail = p;
        ++modCount;
    }
}
```

### afterNodeInsertion(boolean evict)数据插入完成之后
因为removeEldestEntry返回false 所以啥也没做.
```java
void afterNodeInsertion(boolean evict) {
    LinkedHashMapEntry<K, V> first;
    if (evict && (first = head) != null && removeEldestEntry(first)) {
        K key = first.key;
        removeNode(hash(key), key, null, false, true);
    }
}
protected boolean removeEldestEntry(Map.Entry<K,V> eldest) {
    return false;
}

```

### afterNodeRemoval(Node<K,V> p)数据移除之后
删除双向队列中的节点
```java
void afterNodeRemoval(Node<K, V> e) {
    LinkedHashMapEntry<K, V> p =
            (LinkedHashMapEntry<K, V>) e, b = p.before, a = p.after;
    p.before = p.after = null;
    if (b == null)
        head = a;
    else
        b.after = a;
    if (a == null)
        tail = b;
    else
        a.before = b;
}

```

### get(Object key)
只是在设置了按访问顺序排序时调用了afterNodeAccess方法，来做双向链表的变化操作
```java
public V get(Object key) {
    Node<K,V> e;
    if ((e = getNode(hash(key), key)) == null)
        return null;
    if (accessOrder)
        afterNodeAccess(e);
    return e.value;
}

public V getOrDefault(Object key, V defaultValue) {
    Node<K,V> e;
    if ((e = getNode(hash(key), key)) == null)
        return defaultValue;
    if (accessOrder)
        afterNodeAccess(e);
    return e.value;
}
```