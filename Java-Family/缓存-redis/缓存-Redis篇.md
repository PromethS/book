## 数据结构

![img](https://520li.oss-cn-hangzhou.aliyuncs.com/img/640.png)

### String

Redis 中的字符串是一种 **动态字符串**，这意味着使用者可以修改，它的底层实现有点类似于 Java 中的 **ArrayList**，有一个字符数组，从源码的 **sds.h/sdshdr 文件** 中可以看到 Redis 底层对于字符串的定义 **SDS**。

**Redis 为了对内存做极致的优化，不同长度的字符串使用不同的结构体来表示。**当字符串比较短的时候，可以使用 byte 和 short 来表示。

#### 基本操作

1. **Get** key： 获取指定 key 的值。
2. **Set** key value：设置指定 key 的值
3. **GetSet** key value：将给定 key 的值设为 value ，并返回 key 的旧值(old value)
4. **MGet** key1 [key2...]：获取所有(一个或多个)给定 key 的值
5. **MSet** key value [key value...]：同时设置一个或多个 key-value 对
6. **SetEx** key seconds value：将值 value 关联到 key ，并将 key 的过期时间设为 seconds (以秒为单位)
7. **SetNX** key value：只有在 key 不存在时设置 key 的值。用于**分布式锁**
8. **MSetNX** key value [key value...]：同时设置一个或多个 key-value 对，**当且仅当所有给定 key 都不存在**
9. **Incr** key：将 key 中储存的数字值增一
10. **Incrby** key increment：将 key 所储存的值加上给定的增量值（increment）
11. **Decr** key：将 key 中储存的数字值减一
12. **Decrby** key decrement：key 所储存的值减去给定的减量值（decrement）
13. **Append**  key value：如果 key 已经存在并且是一个字符串， APPEND 命令将指定的 value 追加到该 key 原来值（value）的末尾
14. **StrLen** key：返回 key 所储存的字符串值的长度

##### 设置和获取键值对

```powershell
> SET key value
OK
> GET key
"value"
```

我们通常使用 `SET` 和 `GET` 来设置和获取字符串值。

值可以是任何种类的字符串（包括二进制数据），例如你可以在一个键下保存一张 `.jpeg` 图片，只需要注意不要超过 **512 MB 的最大限度**就好了。

另外你还可以使用 `EXISTS` 和 `DEL` 关键字来查询是否存在和删除键值对：

```powershell
> EXISTS key
(integer) 1
> DEL key
(integer) 1
> GET key
(nil)
```

##### 批量设置键值对

```powershell
> SET key1 value1
OK
> SET key2 value2
OK
> MGET key1 key2 key3    # 返回一个列表
1) "value1"
2) "value2"
3) (nil)
> MSET key1 value1 key2 value2
> MGET key1 key2
1) "value1"
2) "value2"
```

##### 过期和 SET 命令扩展

可以对 key 设置过期时间，到时间会被自动删除，这个功能常用来控制缓存的失效时间。(**过期可以是任意数据结构**)

也可以使用`senex`在设置时直接加上过期时间

```powershell
> SET key value1
> GET key
"value1"
> EXPIRE name 5    # 5s 后过期
...                # 等待 5s
> GET key
(nil)
> SETEX key value 5 # 5s 后过期
```

等价于 `SET` + `EXPIRE` 的 `SETNX` 命令：

```powershell
> SETNX key value1
...                # 等待 5s 后获取
> GET key
(nil)

> SETNX key value1  # 如果 key 不存在则 SET 成功
(integer) 1
> SETNX key value1  # 如果 key 存在则 SET 失败
(integer) 0
> GET key
"value"             # 没有改变
```

##### 计数

如果 value 是一个整数，还可以对它使用 `INCR` 命令进行 **原子性** 的自增操作，这意味着及时多个客户端对同一个 key 进行操作，也决不会导致竞争的情况：

```powershell
> SET counter 100
> INCR count
(interger) 101
> INCRBY counter 50
(integer) 151
```

##### 返回原值的 GETSET 命令

对字符串，还有一个 `GETSET` 比较让人觉得有意思，它的功能跟它名字一样：为 key 设置一个值并返回原值：

```powershell
> SET key value
> GETSET key value1
"value"
```

这可以对于某一些需要隔一段时间就统计的 key 很方便的设置和查看，例如：系统每当由用户进入的时候你就是用 `INCR` 命令操作一个 key，当需要统计时候你就把这个 key 使用 `GETSET` 命令重新赋值为 0，这样就达到了统计的目的。

#### 应用场景

- **缓存功能：String**字符串是最常用的数据类型，不仅仅是**Redis**，各个语言都是最基本类型，因此，利用**Redis**作为缓存，配合其它数据库作为存储层，利用**Redis**支持高并发的特点，可以大大加快系统的读写速度、以及降低后端数据库的压力。
- **计数器：许多系统都会使用Redis**作为系统的实时计数器，可以快速实现计数和查询的功能。而且最终的数据结果可以按照特定的时间落地到数据库或者其它存储介质当中进行永久保存。
- **共享用户Session：用户重新刷新一次界面，可能需要访问一下数据进行重新登录，或者访问页面缓存Cookie**，但是可以利用**Redis**将用户的**Session**集中管理，在这种模式只需要保证**Redis**的高可用，每次用户**Session**的更新和获取都可以快速完成。大大提高效率。

### 列表List

Redis 的列表相当于 Java 语言中的 **LinkedList**，注意它是链表而不是数组。这意味着 list 的插入和删除操作非常快，时间复杂度为 O(1)，但是索引定位很慢，时间复杂度为 O(n)。

![img](https://520li.oss-cn-hangzhou.aliyuncs.com/img/640.jpg)

#### 链表的基本操作

1. **LPush** key value1 [value2...]：将一个或多个值插入到列表**头部**
2. **LPushX** key value：将一个值插入到已存在的列表头部
3. **RPush** key value1 [value2...]：在列表中添加一个或多个值
4. **RPushX** key value：为已存在的列表添加值
5. **LSet** key index value：通过索引设置列表元素的值
6. **LPop** key：移出并获取列表的第一个元素
7. **BLPop** key1 [key2...] timeout：移出并获取列表的第一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止
8. **RPop** key：移除列表的最后一个元素，返回值为移除的元素。
9. **BRPop** key1 [key2...] timeout：移出并获取列表的最后一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止
10. **LIndex** key index：通过索引获取列表中的元素
11. **LLen** key：获取列表长度
12. **LRange** key start stop：获取列表指定范围内的元素

总结：

- `LPUSH` 和 `RPUSH` 分别可以向 list 的左边（头部）和右边（尾部）添加一个新元素；
- `LPOP`和`RPOP`分别可以从list的左边（头部）和右边（尾部）移出并获取
- `BLPOP`和`BRPOP`分别可以从list的左边（头部）和右边（尾部）移出并获取，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止
- `LRANGE` 命令可以从 list 中取出一定范围的元素；
- `LINDEX` 命令可以从 list 中取出指定下表的元素，相当于 Java 链表操作中的 `get(int index)` 操作；

##### list 实现队列

队列是先进先出的数据结构，常用于消息排队和异步逻辑处理，它会确保元素的访问顺序：

```powershell
> RPUSH books python java golang
(integer) 3
> LPOP books
"python"
> LPOP books
"java"
> LPOP books
"golang"
> LPOP books
(nil)
```

##### list 实现栈

栈是先进后出的数据结构，跟队列正好相反：

```powershell
> RPUSH books python java golang
> RPOP books
"golang"
> RPOP books
"java"
> RPOP books
"python"
> RPOP books
(nil)
```

#### 应用场景

**List**本身就是我们在开发过程中比较常用的数据结构了，热点数据更不用说了。

- **消息队列：Redis**的链表结构，可以轻松实现阻塞队列，可以使用左进右出的命令组成来完成队列的设计。比如：数据的生产者可以通过**Lpush**命令从左边插入数据，多个数据消费者，可以使用**BRpop**命令阻塞的“抢”列表尾部的数据。

- 文章列表或者数据分页展示的应用。

  比如，我们常用的博客网站的文章列表，当用户量越来越多时，而且每一个用户都有自己的文章列表，而且当文章多时，都需要分页展示，这时可以考虑使用**Redis**的列表，列表不但有序同时还支持按照范围内获取元素，可以完美解决分页查询功能。大大提高查询效率。

### 字典Hash

Redis 中的字典相当于 Java 中的 **HashMap**，内部实现也差不多类似，都是通过 **"数组 + 链表"** 的链地址法来解决部分 **哈希冲突**，同时这样的结构也吸收了两种不同数据结构的优点。

从源码上可以看到，**实际上字典结构的内部包含两个 hashtable**，通常情况下只有一个 hashtable 是有值的，但是在字典扩容缩容时，需要分配新的 hashtable，然后进行 **渐进式rehash**

#### 渐进式 rehash

大字典的扩容是比较耗时间的，需要重新申请新的数组，然后将旧字典所有链表中的元素重新挂接到新的数组下面，这是一个 O(n) 级别的操作，作为单线程的 Redis 很难承受这样耗时的过程，所以 Redis 使用 **渐进式 rehash** 小步搬迁：

渐进式 rehash 会在 rehash 的同时，保留新旧两个 hash 结构，查询时会同时查询两个 hash 结构，然后在后续的定时任务以及 **hash 操作指令**中，循序渐进的把旧字典的内容迁移到新字典中。当搬迁完成了，就会使用新的 hash 结构取而代之。

##### 扩容的条件

正常情况下，当 hash 表中 **元素的个数等于第一维数组的长度时**，就会开始扩容，扩容的新数组是 **原数组大小的 2 倍**。不过如果 Redis 正在做 `bgsave(持久化命令)`，为了减少内存也得过多分离，Redis 尽量不去扩容，但是如果 hash 表非常满了，**达到了第一维数组长度的 5 倍了**，这个时候就会 **强制扩容**。

##### 缩容的条件

当 hash 表因为元素逐渐被删除变得越来越稀疏时，Redis 会对 hash 表进行缩容来减少 hash 表的第一维数组空间占用。所用的条件是 **元素个数低于数组长度的 10%**，缩容不会考虑 Redis 是否在做 `bgsave`。

##### 实现步骤

- 为 ht[1] 分配空间， 让字典**同时持有 ht[0] 和 ht[1] 两个哈希表**。
- 在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。
- 在 rehash 进行期间， 每次对字典执行**添加、删除、查找或者更新操作**时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。
- 随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为 -1 ， 表示 rehash 操作已完成。

##### 优缺点

- 优点：避免了redis阻塞，**在扩容时不影响读写**
- 缺点：在rehash期间，需要先在table[0]上查找，如果没找到的话再去table[1]。由于两个hash表同时在使用，**会导致内存使用量瞬间突增**，**在redis满容状态下由于rehash会导致大量的key驱逐**

> JUC的ConcurrentHashMap在JDK 1.8中增加了**多线程扩容机制**，增加了ForwardingNode（标识扩容状态，在原table上），有点类似于Redis Hash的渐进式扩容。
>
> - 在get时，如果节点有数据，则直接返回数据，如果节点无数据，且被设置fwd节点，则**当前get线程参与扩容**
> - 在put/remove时，如果此时链表**已迁移完成**（fwd节点），此时会参与扩容，如果扩容没有完成，则当前链表的头部会被锁住，所以**写线程被堵塞，直到扩容完成**

#### 字典的基本操作

**hash 也有缺点，hash 结构的存储消耗要高于单个字符串，并且无法单独设置field的过期时间**，所以到底该使用 hash 还是字符串，需要根据实际情况再三权衡。

1. **HGet** key field：获取存储在哈希表中指定字段的值
2. **HSet** key field value：将哈希表 key 中的字段 field 的值设为 value
3. **HDel** key field [field2...]：删除一个或多个哈希表字段
4. **HExists** key field：查看哈希表 key 中，指定的字段是否存在
5. **HGetAll** key：获取在哈希表中指定 key 的所有字段和值
6. **HKeys** key：获取所有哈希表中的字段
7. **HIncrBy** key field increment： 为哈希表 key 中的指定字段的整数值加上增量 increment 
8. **HLen** key：获取哈希表中字段的数量
9. **HMGet** key field [field2...]：获取所有给定字段的值
10. **HMSet** key field value [field2 value2...]：同时将多个 field-value (域-值)对设置到哈希表 key 中
11. **HSetNX** key field：只有在字段 field 不存在时，设置哈希表字段的值

```powershell
> HSET books java "think in java"    # 命令行的字符串如果包含空格则需要使用引号包裹
(integer) 1
> HSET books python "python cookbook"
(integer) 1
> HGETALL books    # key 和 value 间隔出现
1) "java"
2) "think in java"
3) "python"
4) "python cookbook"
> HGET books java
"think in java"
> HSET books java "head first java"  
(integer) 0        # 因为是更新操作，所以返回 0
> HMSET books java "effetive  java" python "learning python"    # 批量操作
OK
```

#### 应用场景

Hash的场景其实还是多少单一了一些，因为现在很多对象都是比较复杂的，比如你的商品对象可能里面就包含了很多属性，其中也有对象。一般用来保存一些**简单的对象**，有多个属性。

### 集合Set

Redis 的集合相当于 Java 语言中的 **HashSet**，它内部的键值对是无序、唯一的。它的内部实现相当于一个特殊的字典，字典中所有的 value 都是一个值 NULL。

#### 集合 set 的基本使用

1. **SAdd** key member1 [member2...]：向集合添加一个或多个成员
2. **SCard** key：获取集合的成员数
3. **SPop** key：移除并返回集合中的一个随机元素
4. **SRem** key member1 [member2...]：移除集合中一个或多个成员
5. **SMembers** key：返回集合中的所有成员
6. **SDiff** key1 [key2]：返回给定所有集合的**差集**
7. **SDiffStore** destination key1 [key2...]：返回给定所有集合的差集并存储在 destination 中
8. **SInter** key1 [key2]：返回给定所有集合的**交集**
9. **SInterStore** destination key1 [key2...]：返回给定所有集合的交集并存储在 destination 中
10. **SUnion** key1 [key2]：返回所有给定集合的**并集**

```powershell
> SADD books java
(integer) 1
> SADD books java    # 重复
(integer) 0
> SADD books python golang
(integer) 2
> SMEMBERS books    # 注意顺序，set 是无序的
1) "java"
2) "python"
3) "golang"
> SISMEMBER books java    # 查询某个 value 是否存在，相当于 contains
(integer) 1
> SCARD books    # 获取长度
(integer) 3
> SPOP books     # 弹出一个
"java"
```

#### 应用场景

可以基于 **Set** 玩儿**交集、并集、差**集的操作，比如交集吧，我们可以把两个人的好友列表整一个交集，看看俩人的共同好友是谁。这些场景比较多，因为对比很快，操作也简单，两个查询一个**Set**搞定

### 有序集合ZSet

这可能使 Redis 最具特色的一个数据结构了，它类似于 Java 中 **SortedSet** 和 **HashMap** 的结合体，一方面它是一个 set，保证了内部 value 的唯一性，另一方面它可以为每个 value 赋予一个 **score 值，用来代表排序的权重**。

它的内部实现用的是一种叫做 **「跳跃表」** 的数据结构。详见【跳跃表-Redis】

#### 有序列表 zset 基础操作

1. **ZAdd** key score1 member1 [score2 member2...]：向有序集合添加一个或多个成员，或者更新已存在成员的分数
2. **ZCard** key：获取有序集合的成员数
3. **ZRem** key member1 [member2...]：移除有序集合中的一个或多个成员
4. **ZScore** key member：返回有序集中，成员的分数值
5. **ZRank** key member：返回有序集合中指定成员的索引（排名）
6. **ZRange** key start stop：通过索引区间返回有序集合指定区间内的成员
7. **ZRevRange** key start stop：返回有序集中指定区间内的成员，通过索引，分数从高到低

```powershell
> ZADD books 9.0 "think in java"
> ZADD books 8.9 "java concurrency"
> ZADD books 8.6 "java cookbook"

> ZRANGE books 0 -1     # 按 score 排序列出，参数区间为排名范围
1) "java cookbook"
2) "java concurrency"
3) "think in java"

> ZREVRANGE books 0 -1  # 按 score 逆序列出，参数区间为排名范围
1) "think in java"
2) "java concurrency"
3) "java cookbook"

> ZCARD books           # 相当于 count()
(integer) 3

> ZSCORE books "java concurrency"   # 获取指定 value 的 score
"8.9000000000000004"                # 内部 score 使用 double 类型进行存储，所以存在小数点精度问题

> ZRANK books "java concurrency"    # 排名
(integer) 1

> ZRANGEBYSCORE books 0 8.91        # 根据分值区间遍历 zset
1) "java cookbook"
2) "java concurrency"

> ZRANGEBYSCORE books -inf 8.91 withscores  # 根据分值区间 (-∞, 8.91] 遍历 zset，同时返回分值。inf 代表 infinite，无穷大的意思。
1) "java cookbook"
2) "8.5999999999999996"
3) "java concurrency"
4) "8.9000000000000004"

> ZREM books "java concurrency"             # 删除 value
(integer) 1
> ZRANGE books 0 -1
1) "java cookbook"
2) "think in java"
```

#### 应用场景

- 排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。
- 用**Sorted Sets**来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。

### 总结

![image-20200520232958316](https://520li.oss-cn-hangzhou.aliyuncs.com/img/image-20200520232958316.png)

## 高级用法

### Bitmap

位图是支持按 bit 位来存储信息，可以用来实现 **布隆过滤器（BloomFilter）**；

### HyperLogLog

供不精确的去重计数功能，比较适合用来做大规模数据的去重统计，例如统计 UV；

### Geospatial

可以用来保存地理位置，并作位置距离计算或者根据半径计算位置等。有没有想过用Redis来实现附近的人？或者计算最优地图路径？

这三个其实也可以算作一种数据结构，不知道还有多少朋友记得，我在梦开始的地方，Redis基础中提到过，你如果只知道五种基础类型那只能拿60分，如果你能讲出高级用法，那就觉得你**有点东西**。

### pub/sub

功能是订阅发布功能，可以用作简单的消息队列。

### Pipeline

可以批量执行一组指令，一次性返回全部结果，可以减少频繁的请求应答。

### Lua

**Redis** 支持提交 **Lua** 脚本来执行一系列的功能。

秒杀场景中用的比较多，利用它的原子性。

### 事务

最后一个功能是事务，但 **Redis** 提供的不是严格的事务，**Redis** 只保证串行执行命令，并且能保证全部执行，但是执行命令失败时并不会回滚，而是会继续执行下去。

## 16个数据库

Redis是一个字典结构的存储服务器，而实际上一个Redis实例提供了**多个用来存储数据的字典**，客户端可以指定将数据存储在哪个字典中。这与我们熟知的在一个关系数据库实例中可以创建多个数据库类似，所以可以将其中的每个字典都理解成一个独立的数据库。

每个数据库对外都是一个从0开始的递增数字命名，Redis默认**支持16个数据库**（可以通过配置文件支持更多，无上限），可以通过配置databases来修改这一数字。客户端与Redis建立连接后会自动选择0号数据库，不过可以随时使用SELECT命令更换数据库。

但是与常规的mysql数据库概念是不同的：

- Redis**不支持自定义数据库的名字**，每个数据库都以编号命名，开发者必须自己记录哪些数据库存储了哪些数据。
- Redis也**不支持为每个数据库设置不同的访问密码**，所以一个客户端要么可以访问全部数据库，要么连一个数据库也没有权限访问。
- 最重要的一点是多个数据库之间**并不是完全隔离的**，比如FLUSHALL命令可以清空一个Redis实例中所有数据库中的数据。

综上所述，这些数据库更像是一种**命名空间**，而**不适宜存储不同应用程序的数据**。比如可以使用0号数据库存储某个应用生产环境中的数据，使用1号数据库存储测试环境中的数据，但不适宜使用0号数据库存储A应用的数据而使用1号数据库B应用的数据，不同的应用应该使用不同的Redis实例存储数据。由于Redis**非常轻量级**，一个空Redis实例占用的内在只有1M左右，所以不用担心多个Redis实例会额外占用很多内存。 

## 为什么速度快

**Redis**采用的是基于内存的**单进程单线程**模型的 KV 数据库，由C语言编写，官方提供的数据是可以达到10W+的**QPS（每秒内查询次数）**。

- **完全基于内存**，绝大部分请求是纯粹的内存操作，非常快速。它的，数据存在内存中，类似于**HashMap**，**HashMap**的优势就是查找和操作的时间复杂度都是O(1)；
- **数据结构简单**，对数据操作也简单，**Redis**中的数据结构是专门进行设计的；
- **采用单线程，避免了不必要的上下文切换和竞争条件**，也不存在多进程或者多线程导致的切换而消耗 **CPU**，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；
- **使用多路I/O复用模型**，非阻塞IO，**epoll模型**；
- 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，**Redis**直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；

## 持久化

**Redis** 提供了 RDB 和 AOF 两种持久化方式，RDB 是；AOF 是以文本日志的形式记录 **Redis** 处理的每一个写入或删除操作。

### RDB

- 优点

  把内存中的数据集以快照形式写入磁盘，实际操作是通过 **fork 子进程**执行，采用二进制压缩存储，**RDB**对**Redis**的**性能影响非常小**，而且他在**数据恢复**的时候速度比**AOF**来的快。比较适合做**冷备**。

- 缺点

  **RDB**都是快照文件，都是默认五分钟甚至更久的时间才会生成一次，这意味着你这次同步到下次同步这中间五分钟的数据都很可能全部丢失掉。**AOF**则最多丢一秒的数据，**数据完整性**上高下立判。

  还有就是**RDB**在生成数据快照的时候，如果文件很大，客户端可能会**暂停**几毫秒甚至几秒。

### AOF

- 优点

  **AOF** 对日志文件的写入操作使用的是追加模式，少了很多磁盘寻址的开销了，写入性能惊人。

  有**灵活的同步策略，支持每秒同步、每次修改同步和不同步**。

- 缺点

  相同规模的数据集，AOF 文件要大于 RDB，在数据恢复时速度较慢。

  AOF开启后，对性能有一定的影响。如果开启每次修改同步，则影响更大。

**RDB**更适合做**冷备**，**AOF**更适合做**热备**，一般情况下都会同时开启。

**两种机制全部开启的时候，Redis在重启的时候会默认使用AOF去重新构建数据，因为AOF的数据是比RDB更完整的。**

## 常见问题

### 缓存穿透

缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，我们数据库的 id 都是1开始自增上去的，如发起为id值为 -1 的数据或 id 为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大，严重会击垮数据库。

解决办法：

- **参数校验**。过滤非法的参数，比如ID小于0，分页时传入的数据条数非常大。
- **缓存null值**。当DB查询不到时，将一个空对象缓存起来，设置一个比较短的过期时间。
- **使用布隆过滤器（Bloom Filter）**。基于布隆过滤器可以快速判断数据是否存在，只有存在时再去查数据库。

### 缓存击穿

**缓存击穿**跟**缓存雪崩**有点像，但是又有一点不一样，缓存雪崩是因为大面积的缓存失效，打崩了DB，而缓存击穿指的是一个Key非常热点，在不停的扛着大并发，当这个Key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个完好无损的桶上凿开了一个洞。

解决办法：

- **使用分布式锁**：当缓存不存在时，需要查DB时用分布式锁，并且使用双重锁检查，可以避免大请求到DB。
- **设置永不过期**：针对热点数据可以设置永不过期。

### 缓存雪崩

同一时间缓存大面积失效，导致大并发请求落到DB上。比如：电商首页或热点数据都会去做缓存 ，一般缓存都是定时任务去刷新，将有较大可能同一时间过期。

解决办法：

- **随机时间**：在批量设置缓存时，在原有的过期时间上增加一定的随机时间。避免同时失效。
- **设置永不过期**：针对热点数据可以设置永不过期。

### 脑裂

![](https://520li.oss-cn-hangzhou.aliyuncs.com/img/20190724145412307.png)

如果此时master服务器所在区域网络通信出现异常，导致和两台slave机器无法正常通信，但是和客户端的连接是正常的。那么sentinel就会从两台slave机器中选举其中一个作为新的master来处理客户端请求。

这个时候，将**存在两台master服务器**，client发送的数据会持续保存在旧的master服务器中，而新的master和slave中没有新的数据。如果一分钟以后，网络恢复正常，服务之间能够正常通信。此时，sentinel会把旧的master会变成新的master的slave节点。

这个时候，变成了slave节点的旧master会丢失掉通信异常期间从客户端接收到的数据。

解决办法：

在配置文件中添加如下配置

min-slaves-to-write 1，要求至少有一个slave。

min-slaves-max-lag 10，主从数据同步超时时间，10秒。

以上两个配置，都不满足就会导致**master拒绝接受客户端请求**。根据以上配置可以将master通信异常期间的数据丢失控制在10秒以内。

### 读后写问题

当对**同一个数据**先读取，后写入数据，并且**写依赖读**，在高并发场景下将会出现读后写数据不一致的问题。

比如A、B两个线程同时操作如下代码：

```javascript
$objRedis = new Redis();
//获取key
$intNum   = $objRedis->get('key');
if ($intNum == 1) {
    //如果key的值为1，则给key加1
    $bolRet   = $objRedis->incr('key');

    //do something...
}
```

- 如果A进程先get到了key，而此时key的值为1；
- 同时，B进程此时也get到了key，同样key值为1；
- B进程运行的快，先进行了if判断，发现满足条件，于是对key进行了累加操作，此时key变成了2；
- A进程对B进程修改了key这个操作茫然无知，所以当它继续运行走到if判断条件时，由于它get的key是1，因此也满足条件，于是A进程也会对key进行累加操作，但是由于key已经被B进行累加过一次（key的值已经是2），因此当A再累加，key最终就变成了3。

解决办法：

- 使用**getset**、**incr**。在修改值时再次判断原来的值是否有变更，如果变更了，则需增加**补偿机制**。
- 使用**分布式锁**。对同一个数据操作先加锁，将读写逻辑放到锁里面，避免读后写。
- 使用**lua脚本**。将读写的逻辑封装到lua脚本中，保障原子性操作。

### 缓存一致性问题

最经典的缓存+数据库读写的模式，就是 **Cache Aside Pattern**

- 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。

- 更新的时候，**先更新数据库，然后再删除缓存**。

  > 基于lazy思想，并且更新缓存的代价往往比较大。所以是直接删除缓存，而不是更新缓存

只要用缓存，就可能会涉及到缓存与数据库双存储双写，只要是双写，就一定会有数据一致性的问题。

解决办法：

- 业务上允许在一定时间内的不一致，在设置key时指定过期时间，最差的情况是一定时间内不一致：

  - **延迟双删**：在事务执行前删除缓存，在事务提交后延迟一定时间再次删除缓存。
  - 在事务内提交前使用**expire** key seconds命令，如果设置失败，则使用**setex** key seconds命令，设置一个空对象。该方案是在项目中使用的。

  > 延迟一定时间是为了确保读请求结束，可以删除读请求造成的脏数据。一般可以设置为500ms。

- 对于一致性要求很高，不允许出现不一致情况。

  - **读请求和写请求串行化**，串到一个内存队列里去。串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，并且业务复杂度也会上升。
  - 通过**canal**（阿里巴巴）订阅**binlog**来更新redis。和业务解耦，在mysql压力不大的情况下，延迟比较低，但是引入binlog同步机制成本较大。

## 过期策略

**Redis**的过期策略，是有**定期删除+惰性删除**两种。

- 默认100S随机抽一些设置了过期时间的key，检查是否过期。
- 在查询数据时，如果发现key已经过期，则执行删除，也就是惰性删除。

当redis的内存满了以后，有多种内存淘汰机制：

- **noeviction**:返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但DEL和几个例外）
- **allkeys-lru**: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。
- **volatile-lru**: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放。
- **allkeys-random**: 回收随机的键使得新添加的数据有空间存放。
- **volatile-random**: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。
- **volatile-ttl**: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放。

> 配置redis.conf中的maxmemory这个值来修改内存淘汰方式。一般使用**volatile-ttl**策略
>
> maxmemory-policy volatile-ttl

在redis中不使用真实的LRU实现是因为这需要太多的内存。不过**近似的LRU算法**对于应用而言应该是等价的。在RedisObject中记录key的最新访问时间（lru值），基于当前时间可以计算出空闲时间。

使用随机取样算法，随机取出N个key，淘汰空闲时间最长的key。

在Redis 3.0的时候对算法做了改进了，引入了缓冲池（大顶堆算法，用于求最小值，默认容量16）。接下来每次随机选取的key lru值必须小于pool中最小的lru才会继续放入，直到将pool放满。放满之后，每次如果有新的key需要放入，需要将pool中lru最大的一个key取出。淘汰的时候，直接从pool中选取一个lru最小的值然后将其淘汰。

> 随机选取的key是个可配置的参数maxmemory-samples,默认值为5

LRU算法也可以借助于**LinkedHashMap**实现

![image-20200520001550548](https://520li.oss-cn-hangzhou.aliyuncs.com/img/image-20200520001550548.png)

## 与Memcache比较

- Redis 采用单线程模式处理请求，避免线程同步以及线程上下文切换产生的代价。使用NIO多路复用模型（使用epoll模式）。Memcache使用多线程模式，需要考虑线程安全问题。
- **Redis** 支持持久化，所以 Redis 不仅仅可以用作缓存，也可以用作 NoSQL 数据库。Memcache仅可用于内存数据库，数据无法持久化。
- **Redis** 除了 K-V 之外，还支持多种数据格式，例如 list、set、sorted set、hash 等。而Memcache仅支持K-V结构。
- **Redis** 提供主从同步机制，以及 **Cluster** 集群部署能力，能够提供高可用服务。

## 高可用

### 主从模式

一个master有多个slave，多个Slave可以提供读服务，**读写分离**，但是当master宕机后，slave并不能切换为master，将会导致服务不可用。

使用psync命令完成主从复制过程：

- 全量复制：一般用于初次复制场景（第一次建立SLAVE后全量），将**RDB**快照发送给slave。
- 部分复制：网络出现问题，从节点再次连接主节点时，主节点补发缺少的数据，每次数据增量同步。
- 心跳：主从有长连接心跳，主节点默认每10S向从节点发ping命令，repl-ping-slave-period控制发送频率

缺点：

- 若主节点出现问题，则不能提供服务，需要人工修改配置将从变主
- 主从复制主节点的写能力单机，能力有限
- 单机节点的存储能力也有限

![image-20200520004702529](https://520li.oss-cn-hangzhou.aliyuncs.com/img/image-20200520004702529.png)

### 主从模式+哨兵

哨兵机制的出现是为了**解决主从复制的缺点**的，可以保证服务的**高可用**。当主节点出现故障时，由Redis Sentinel自动完成**故障发现和转移**，并通知应用方，实现高可用性。

sentinel本身也是分布式的，作为一个哨兵集群，sentinel 之间通过 **Raft 协议**来保证自身的高可用。为了保证哨兵集群的高可用，至少需要**三个以上**的实例完成高可用。

哨兵的作用：

- **集群监控**，负责监控redis master和slave进程是否正常工作
- **消息通知**，如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员
- **故障转移**，如果master node挂掉了，会自动转移到slave node上
- **配置中心**，如果故障转移发生了，通知client客户端新的master地址

![image-20200520005043930](https://520li.oss-cn-hangzhou.aliyuncs.com/img/image-20200520005043930.png)

### Cluster集群模式

RedisCluster是redis的**分布式解决方案**，在3.0版本后推出的方案，有效地解决了Redis分布式的需求，当一个服务挂了可以快速的切换到另外一个服务，当遇到**单机内存、并发等瓶颈**时，可使用此方案来解决这些问题。

#### 分区规则

Redis Cluster 使用**虚拟槽分片**机制，在内部分为 **16384 个 slot 插槽**，分布在所有 master 节点上，每个 master 节点负责一部分 slot。数据操作时按 key 做 CRC16 来计算在哪个 slot，由哪个 master 进行处理。数据的冗余是通过 slave 节点来保障。

![image-20200520011913574](https://520li.oss-cn-hangzhou.aliyuncs.com/img/image-20200520011913574.png)



#### 节点之间的通信

节点之间采用Gossip协议进行通信，Gossip协议就是指节点彼此之间不断通信交换信息。

![image-20200520012325041](https://520li.oss-cn-hangzhou.aliyuncs.com/img/image-20200520012325041.png)

- meet消息：用于通知新节点加入，消息发送者通知接收者加入到当前集群，meet消息通信完后，接收节点会加入到集群中，并进行周期性ping pong交换
- ping消息：集群内交换最频繁的消息，集群内每个节点每秒向其它节点发ping消息，用于检测节点是在在线和状态信息，ping消息发送封装自身节点和其他节点的状态数据；
- pong消息，当接收到ping meet消息时，作为响应消息返回给发送方，用来确认正常通信，pong消息也封闭了自身状态数据；
- fail消息：当节点判定集群内的另一节点下线时，会向集群内广播一个fail消息

 Gossip协议信息的交换机制具有天然的分布式特性，但**ping pong发送的频率很高**，可以实时得到其它节点的状态数据，但频率高会加重带宽和计算能力，因此每次都会有目的性地选择一些节点； 但是节点选择过少又会影响故障判断的速度，redis集群的Gossip协议兼顾了这两者的优缺点：

![image-20200520012415014](https://520li.oss-cn-hangzhou.aliyuncs.com/img/image-20200520012415014.png)



#### 故障转移

redis集群实现了高可用，当集群内少量节点出现故障时，通过故障转移可以保证集群正常对外提供服务。

当集群里某个节点出现了问题，redis集群内的节点**通过ping pong消息发现节点是否健康，是否有故障**，其实主要环节也包括了 主观下线和客观下线；

- **主观下线**：指某个节点认为另一个节点不可用，即下线状态，当然这个状态不是最终的故障判定，只能代表这个节点自身的意见，也有可能存在误判；

  ![image-20200520012937975](https://520li.oss-cn-hangzhou.aliyuncs.com/img/image-20200520012937975.png)

  下线流程：

  - 节点a发送ping消息给节点b ,如果通信正常将接收到pong消息，节点a更新最近一次与节点b的通信时间；

  - 如果节点a与节点b通信出现问题则断开连接，下次会进行重连，如果一直通信失败，则它们的最后通信时间将无法更新；**更新本地对节点b的状态为主观下线**（pfail）

- **客观下线**：指真正的下线，集群内多个节点都认为该节点不可用，达成共识，**将它下线**，如果下线的节点为主节点，还要对它进行**故障转移**。

  ![image-20200520013335858](https://520li.oss-cn-hangzhou.aliyuncs.com/img/image-20200520013335858.png)

  - 假如节点a标记节点b为主观下线，一段时间后节点a通过消息把节点b的状态**发到其它节点**，当节点c接受到消息并解析出消息体时，会发现节点b的pfail状态时，会触发客观下线流程；
  - 当**下线为主节点时**，此时redis集群为统计持有槽的**主节点投票数是否达到一半**，当下线报告统计数大于一半时，被标记为客观下线状态。

#### 故障恢复

故障主节点下线后，如果下线节点的是主节点，则需要在它的从节点中选一个替换它，保证集群的高可用；**转移过程**如下：

![image-20200520013625497](https://520li.oss-cn-hangzhou.aliyuncs.com/img/image-20200520013625497.png)

1. 资格检查：检查该从节点是否有资格替换故障主节点，如果此从节点与主节点断开过通信，那么当前从节点不具体故障转移；
2. 准备选举时间：当从节点符合故障转移资格后，更新触发故障选举时间，只有到达该时间后才能执行后续流程；
3. 发起选举：当到达故障选举时间时，进行选举；
4. 选举投票：只有持有槽的主节点才有票，会处理故障选举消息，投票过程其实是一个领导者选举（选举**从节点为领导者**）的过程，每个主节点只能投一张票给从节点，当从节点收集到足够的选票（大于N/2+1）后，触发替换主节点操作，撤销原故障主节点的槽，委派给自己，并广播自己的委派消息，通知集群内所有节点。

#### 缺点

- 键的批量操作支持有限，比如mset, mget，如果多个键映射在不同的槽，就不支持了 
- 键事务支持有限，当多个key分布在不同节点时无法使用事务，同一节点是支持事务
- 键是数据分区的最小粒度，不能将一个很大的键值对映射到不同的节点
- **不支持多数据库**，只有0，select 0
- 复制结构只支持单层结构，不支持树型结构。

## 秒杀场景

秒杀是一个典型的场景，面对瞬时高并发情况下，如何保障系统的可用性，数据的一致性，是一个系统性的问题。针对秒杀场景下需要考虑的点：

- **高并发**

  秒杀的特点就是**时间极短**、 **瞬间用户量大**。大量的请求进来，我们需要考虑的点就很多了，包括**缓存雪崩**，**缓存击穿**，**缓存穿透**。如果出现缓存失效，请求打到DB上肯定会出现宕机情况。

  在并发特别高的情况下，并且大部分场景是**查多写少**，分布式缓存架构也有可能会撑不住，这时可以考虑**多级缓存**，减少连接的耗时，**定时更新数据同步到本地缓存中**。

- **超卖**

  超卖是电商系统的典型问题，解决办法也有很多。

  基于Mysql的解决办法：

  - **乐观锁**，在update时增加where条件，如update prod set stock = stock - 1 where stock>=1 and id=1
  - **悲观锁**，在select时增加排他锁(for update)

  基于缓存的解决办法：

  - 使用**lua脚本的原子性特性**，或使用**incr原子性命令**。

- **库存预热**

  **秒杀的本质，就是对库存的抢夺**，可以提前把商品的库存信息放到**（多级）缓存**中，避免秒杀开启后到DB查询。

- **恶性请求**

  对**请求的参数进行预校验**，防止一些非法参数的请求。

- **链接暴漏**

  如果链接暴漏的话，可能出现使用脚本不停请求，会影响秒杀活动的公平性，并且带来服务器的压力。可以使用**动态链接**，基于用户信息及时间生成一个加密的参数，如果请求时参数不合法则直接拒绝。

- **限流&降级熔断**

  可以使用阿里的sentinel组件做服务限流，控制请求的流量做**限流**，如果服务的RT（平均响应时间）、异常比例、异常数等指标出现问题时，可以做**降级熔断**，保证服务的可用性，不至于被流量打挂掉。

- **服务隔离**

  秒杀服务最好是单独的一个微服务，使用MQ等方式减少与其他服务的耦合性，避免秒杀服务挂掉后影响整个系统的使用。

- **削峰填谷**

  下单扣减库存等操作可以使用**消息队列MQ**，达到削峰填谷的效果，避免压垮服务。

## Bloom Filter-布隆过滤器

布隆过滤器（英语：Bloom Filter）是1970年由一个叫布隆的小伙子提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是**空间效率和查询时间**都远远超过一般的算法，缺点是**有一定的误识别率和删除困难**。

布隆过滤器的原理是，当一个元素被加入集合时，**通过K个散列函数**将这个元素映射成一个位数组中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。这就是布隆过滤器的基本思想。

Bloom Filter跟**单哈希函数Bit-Map（位图算法）**不同之处在于：Bloom Filter使用了k个哈希函数，每个字符串跟k个bit对应。从而降低了冲突的概率。

![image-20200520234919104](https://520li.oss-cn-hangzhou.aliyuncs.com/img/image-20200520234919104.png)

**缺点：**

- **存在误判**，可能要查到的元素并没有在容器中，但是hash之后得到的k个位置上值都是1。如果bloom filter中存储的是黑名单，那么可以通过建立一个白名单来存储可能会误判的元素。
- **删除困难**。一个放入容器的元素映射到bit数组的k个位置上是1，删除的时候不能简单的直接置为0，可能会影响其他元素的判断。可以采用Counting Bloom Filter
- **需要预估算容量大小**。由于无法扩展计数布隆过滤器表，因此必须事先知道要同时存储在过滤器中的最大键数。一旦超过表的设计容量，随着插入更多密钥，误报率将迅速增长。

**实现：**

- **Guava**中提供了一种Bloom Filter的实现
- **Redisson**提供了Bloom Filter实现

**应用场景：**

- **缓存穿透**。可以使用布隆过滤器预先判断数据是否存在，可以避免请求落到DB上。
- 爬虫过滤已抓到的url就不再抓，可用bloom filter过滤
- **垃圾邮件过滤**。如果用哈希表，每存储一亿个 email地址，就需要 1.6GB的内存（用哈希表实现的具体办法是将每一个 email地址对应成一个八字节的信息指纹，然后将这些信息指纹存入哈希表，由于哈希表的存储效率一般只有 50%，因此一个 email地址需要占用十六个字节。一亿个地址大约要 1.6GB，即十六亿字节的内存）。因此存贮几十亿个邮件地址可能需要上百 GB的内存。而Bloom Filter只需要哈希表 1/8到 1/4 的大小就能解决同样的问题。



## HyperLogLog



## Stream